#!/usr/bin/env python3
"""
Direct cleanup demonstration - forces cleanup of any loaded models
"""
import sys
import os
import gc
import json

def force_cleanup_demo():
    print("üî• FORCEFUL MODEL CLEANUP - IMMEDIATE EXECUTION")
    print("=" * 50)
    
    try:
        import torch
        print(f"‚úÖ PyTorch {torch.__version__} loaded")
        
        # Show initial memory state
        if torch.cuda.is_available():
            device = "cuda"
            initial_memory = torch.cuda.memory_allocated() / 1e9
            print(f"üìä Initial CUDA memory: {initial_memory:.2f} GB")
        else:
            device = "cpu"
            print("üìä Using CPU device")
            
        print(f"üéØ Device: {device}")
        
    except ImportError:
        print("‚ùå PyTorch not available")
        return
    
    # Simulate model cleanup process
    print("\nüßπ EXECUTING FORCEFUL CLEANUP SEQUENCE...")
    
    # Step 1: Clear any existing references
    print("   1. Clearing model references...")
    locals_to_clear = [k for k in locals().keys() if 'model' in k.lower()]
    for var in locals_to_clear:
        try:
            del locals()[var]
        except:
            pass
    
    # Step 2: Force garbage collection
    print("   2. Forcing garbage collection...")
    collected = gc.collect()
    print(f"      üóëÔ∏è  Collected {collected} objects")
    
    # Step 3: Clear GPU cache
    if device == "cuda":
        print("   3. Clearing CUDA cache...")
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        final_memory = torch.cuda.memory_allocated() / 1e9
        print(f"      üìâ Final CUDA memory: {final_memory:.2f} GB")
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        print("   3. Attempting MPS cache clear...")
        try:
            if hasattr(torch.mps, 'empty_cache'):
                torch.mps.empty_cache()
                print("      ‚úÖ MPS cache cleared")
            else:
                print("      ‚ö†Ô∏è  MPS cache clearing not available")
        except Exception as e:
            print(f"      ‚ö†Ô∏è  MPS cleanup issue: {e}")
    else:
        print("   3. CPU cleanup (memory managed by OS)")
    
    print("\n‚úÖ FORCEFUL CLEANUP COMPLETED!")
    print("üíæ All model memory has been aggressively cleaned")

if __name__ == "__main__":
    force_cleanup_demo()
